{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAl7/J5vtlu+cwtrSGM+EL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenmech057/MLproject/blob/main/text_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSb4JH8UwLsT",
        "outputId": "4aa8efb3-cacd-45f8-cd52-e2d7e947394e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "We're LaRninG1 natural-LAnguage-processing!\n",
            "In this\\ example We are goIng to Learn various text9 processing steps.\n",
            "I'm GoIng To-Mr.Rich.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-3976665046.py:3: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  In this\\ example We are goIng to Learn various text9 processing steps.\n"
          ]
        }
      ],
      "source": [
        "raw_text = \"\"\"\n",
        "We're LaRninG1 natural-LAnguage-processing!\n",
        "In this\\ example We are goIng to Learn various text9 processing steps.\n",
        "I'm GoIng To-Mr.Rich.\"\"\"\n",
        "\n",
        "print(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "print(string.ascii_uppercase)\n",
        "print(string.ascii_lowercase)\n",
        "print(string.ascii_letters)\n",
        "print(string.digits)\n",
        "print(string.printable)\n",
        "print(string.punctuation)\n",
        "print(string.whitespace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBXRKW49x_nS",
        "outputId": "784c92db-85cb-412e-cc60-a916b6562f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
            "abcdefghijklmnopqrstuvwxyz\n",
            "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
            "0123456789\n",
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            " \t\n",
            "\r\u000b\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRK4k-sHxSPF",
        "outputId": "1053b793-d79b-4484-96a2-195ec7d59747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now use module to clear up all punctuations\n",
        "\n",
        "text = \"\".join([char for char in raw_text if char not in string.punctuation and not char.isdigit()])\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0GL787hxxLk",
        "outputId": "aa3b1d96-a05b-488a-f65e-66f6ce78a26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Were LaRninG naturalLAnguageprocessing\n",
            "In this example We are goIng to Learn various text processing steps\n",
            "Im GoIng ToMrRich\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a more powerful weapon to remove special charectes"
      ],
      "metadata": {
        "id": "1mEqUlKS0408"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "6aOne5XxzY5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets define a regex to match special characters and digits\n",
        "regex = \"[^a-zA-Z.!]\"\n",
        "text = re.sub(regex,\" \",raw_text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JCWCOf9z5Rw",
        "outputId": "2e88ffd6-bbe4-4a7c-80fa-6533ce63c466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " We re LaRninG  natural LAnguage processing! In this  example We are goIng to Learn various text  processing steps. I m GoIng To Mr.Rich.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.converting to lower case\n"
      ],
      "metadata": {
        "id": "AYtE86AI2QRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change sentance to lower case\n",
        "text = text.lower()\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_oghg3z2ST6",
        "outputId": "a5296051-a889-4590-a774-5b64aec05c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " we re larning  natural language processing! in this  example we are going to learn various text  processing steps. i m going to mr.rich.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.tokenization(sentance and work tokenization"
      ],
      "metadata": {
        "id": "0PK4ZMDs2qua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split(\" \")\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJsrrkPG2oJu",
        "outputId": "1d88adf3-1ee8-4f2a-9401-43fe18a902f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'we', 're', 'larning', '', 'natural', 'language', 'processing!', 'in', 'this', '', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', '', 'processing', 'steps.', 'i', 'm', 'going', 'to', 'mr.rich.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text.split(\".\")\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YZg3bOl3BNH",
        "outputId": "5c84b74d-5ff0-4ab0-ecac-cd079d25701f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' we re larning  natural language processing! in this  example we are going to learn various text  processing steps', ' i m going to mr', 'rich', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wpw89aV13MDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "introducing NLTK\n"
      ],
      "metadata": {
        "id": "ZC1EvsNL3iEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "D6kGtn1F3nwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentence tokenization"
      ],
      "metadata": {
        "id": "WBCdh6Iz30UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reT_Gs7E3zUM",
        "outputId": "2c643d7d-6e91-495d-bcf7-3390a066274b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "# tokenize text into sentances\n",
        "my_sentences = sent_tokenize(text)\n",
        "\n",
        "print(my_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPiHZcNw4Mkh",
        "outputId": "73347290-ffc1-4fa6-997f-393dfff5b613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' we re larning  natural language processing!', 'in this  example we are going to learn various text  processing steps.', 'i m going to mr.rich.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "word tokenize"
      ],
      "metadata": {
        "id": "vNL10rq25uLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import  word_tokenize\n",
        "# tokenize text to words\n",
        "words = word_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcDd_CLj5w8a",
        "outputId": "14ef4beb-fd8a-4262-d023-31bfcb321e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "# tokenize sentence to words\n",
        "for sentance in sent_tokenize(text):\n",
        "  print(word_tokenize(sentance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K6aRrCK58m4",
        "outputId": "4c2e7000-e55d-4999-89b3-e8e33b082402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['we', 're', 'larning', 'natural', 'language', 'processing', '!']\n",
            "['in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.']\n",
            "['i', 'm', 'going', 'to', 'mr.rich', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.removing stop words"
      ],
      "metadata": {
        "id": "G7bs6W_H7Qjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "id": "ILGppgUK61I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the words corpus\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv3SKzxH7dNK",
        "outputId": "da06284e-589d-4f9b-dc9b-bacc34d858f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"List of stopwords:\")\n",
        "print(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQBIyQG-7nTI",
        "outputId": "1cbed70b-fd1f-414d-b0b6-086132c9cc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of stopwords:\n",
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stop words\n",
        "words = [words for word in words if word not in stopwords.words (\"english\")]\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr6tMlOP8DL1",
        "outputId": "2c7af058-2929-449c-a2a0-be576947f3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.'], ['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'steps', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = nltk.word_tokenize(text.lower())"
      ],
      "metadata": {
        "id": "639wR6viIBRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.stemming"
      ],
      "metadata": {
        "id": "eSN2FxT_8joy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "## initialize the inbuilt stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "clean_tokens_stem = [stemmer.stem(word) for word in words]\n",
        "print(clean_tokens_stem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X46J39jF8adP",
        "outputId": "c34ddaee-1a9d-40d8-d6ce-6407924bc96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['we', 're', 'larn', 'natur', 'languag', 'process', '!', 'in', 'thi', 'exampl', 'we', 'are', 'go', 'to', 'learn', 'variou', 'text', 'process', 'step', '.', 'i', 'm', 'go', 'to', 'mr.rich', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lematization"
      ],
      "metadata": {
        "id": "QFOJct2OCAxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading wordnet before applying lemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qB-LNxA9j4G",
        "outputId": "6fd508e5-ea71-4d67-bcfb-8ba8afa7819f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leammating\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# we can also lemmatizer insated of stmmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "clean_tokens_stem= [lemmatizer.lemmatize(word)for word in words]\n",
        "print(clean_tokens_stem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5a5qRQiCbSl",
        "outputId": "b657509b-ecde-4c29-9369-a3149a2d7536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'processing', 'step', '.', 'i', 'm', 'going', 'to', 'mr.rich', '.']\n"
          ]
        }
      ]
    }
  ]
}